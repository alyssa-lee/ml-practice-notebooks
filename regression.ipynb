{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression on sklearn diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive linear regression approach on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019907 -0.017646  \n",
       "1   -0.039493 -0.068332 -0.092204  \n",
       "2   -0.002592  0.002861 -0.025930  \n",
       "3    0.034309  0.022688 -0.009362  \n",
       "4   -0.002592 -0.031988 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018114  0.044485  \n",
       "439 -0.011080 -0.046883  0.015491  \n",
       "440  0.026560  0.044529 -0.025930  \n",
       "441 -0.039493 -0.004222  0.003064  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data = load_diabetes()\n",
    "diabetes_df = pd.DataFrame(diabetes_data.data, columns=diabetes_data.feature_names)\n",
    "diabetes_target = diabetes_data.target\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes_df, diabetes_target, test_size=0.2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <td>age</td>\n",
       "      <td>sex</td>\n",
       "      <td>bmi</td>\n",
       "      <td>bp</td>\n",
       "      <td>s1</td>\n",
       "      <td>s2</td>\n",
       "      <td>s3</td>\n",
       "      <td>s4</td>\n",
       "      <td>s5</td>\n",
       "      <td>s6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coefficient</th>\n",
       "      <td>-8.07365</td>\n",
       "      <td>-248.849</td>\n",
       "      <td>513.855</td>\n",
       "      <td>293.675</td>\n",
       "      <td>-475.566</td>\n",
       "      <td>213.098</td>\n",
       "      <td>-33.6191</td>\n",
       "      <td>147.19</td>\n",
       "      <td>639.104</td>\n",
       "      <td>86.3394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0        1        2        3        4        5        6  \\\n",
       "feature          age      sex      bmi       bp       s1       s2       s3   \n",
       "coefficient -8.07365 -248.849  513.855  293.675 -475.566  213.098 -33.6191   \n",
       "\n",
       "                  7        8        9  \n",
       "feature          s4       s5       s6  \n",
       "coefficient  147.19  639.104  86.3394  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the linear regression model\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "pd.DataFrame([reg.feature_names_in_, reg.coef_], index=['feature', 'coefficient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2929.8952913182065"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2993.0813104693307"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "split = kf.split(diabetes_df)\n",
    "mse = []\n",
    "X = diabetes_df.values\n",
    "y = diabetes_target\n",
    "for train, test in split:\n",
    "  reg = LinearRegression().fit(X[train], y[train])\n",
    "  y_pred = reg.predict(X[test])\n",
    "  mse.append(mean_squared_error(y[test], y_pred))\n",
    "sum(mse) / len(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800500</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>1.297088</td>\n",
       "      <td>0.459841</td>\n",
       "      <td>-0.929746</td>\n",
       "      <td>-0.732065</td>\n",
       "      <td>-0.912451</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.418531</td>\n",
       "      <td>-0.370989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.039567</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-1.082180</td>\n",
       "      <td>-0.553505</td>\n",
       "      <td>-0.177624</td>\n",
       "      <td>-0.402886</td>\n",
       "      <td>1.564414</td>\n",
       "      <td>-0.830301</td>\n",
       "      <td>-1.436589</td>\n",
       "      <td>-1.938479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.793307</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>0.934533</td>\n",
       "      <td>-0.119214</td>\n",
       "      <td>-0.958674</td>\n",
       "      <td>-0.718897</td>\n",
       "      <td>-0.680245</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>-0.545154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.872441</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-0.243771</td>\n",
       "      <td>-0.770650</td>\n",
       "      <td>0.256292</td>\n",
       "      <td>0.525397</td>\n",
       "      <td>-0.757647</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>0.476983</td>\n",
       "      <td>-0.196823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113172</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-0.764944</td>\n",
       "      <td>0.459841</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.327890</td>\n",
       "      <td>0.171178</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>-0.672502</td>\n",
       "      <td>-0.980568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.876870</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>0.413360</td>\n",
       "      <td>1.256040</td>\n",
       "      <td>-0.119769</td>\n",
       "      <td>-0.053957</td>\n",
       "      <td>-0.602843</td>\n",
       "      <td>-0.054499</td>\n",
       "      <td>0.655787</td>\n",
       "      <td>0.151508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.115937</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>-0.334410</td>\n",
       "      <td>-1.422086</td>\n",
       "      <td>1.037341</td>\n",
       "      <td>1.664355</td>\n",
       "      <td>-0.602843</td>\n",
       "      <td>0.721302</td>\n",
       "      <td>-0.380819</td>\n",
       "      <td>0.935254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.876870</td>\n",
       "      <td>1.065488</td>\n",
       "      <td>-0.334410</td>\n",
       "      <td>0.363573</td>\n",
       "      <td>-0.785107</td>\n",
       "      <td>-0.290965</td>\n",
       "      <td>-0.525441</td>\n",
       "      <td>-0.232934</td>\n",
       "      <td>-0.985649</td>\n",
       "      <td>0.325674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.956004</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>0.821235</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.343075</td>\n",
       "      <td>0.321306</td>\n",
       "      <td>-0.602843</td>\n",
       "      <td>0.558384</td>\n",
       "      <td>0.936163</td>\n",
       "      <td>-0.545154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.956004</td>\n",
       "      <td>-0.938537</td>\n",
       "      <td>-1.535374</td>\n",
       "      <td>-1.711613</td>\n",
       "      <td>1.760535</td>\n",
       "      <td>0.584649</td>\n",
       "      <td>3.654268</td>\n",
       "      <td>-0.830301</td>\n",
       "      <td>-0.088752</td>\n",
       "      <td>0.064426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.800500  1.065488  1.297088  0.459841 -0.929746 -0.732065 -0.912451   \n",
       "1   -0.039567 -0.938537 -1.082180 -0.553505 -0.177624 -0.402886  1.564414   \n",
       "2    1.793307  1.065488  0.934533 -0.119214 -0.958674 -0.718897 -0.680245   \n",
       "3   -1.872441 -0.938537 -0.243771 -0.770650  0.256292  0.525397 -0.757647   \n",
       "4    0.113172 -0.938537 -0.764944  0.459841  0.082726  0.327890  0.171178   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.876870  1.065488  0.413360  1.256040 -0.119769 -0.053957 -0.602843   \n",
       "438 -0.115937  1.065488 -0.334410 -1.422086  1.037341  1.664355 -0.602843   \n",
       "439  0.876870  1.065488 -0.334410  0.363573 -0.785107 -0.290965 -0.525441   \n",
       "440 -0.956004 -0.938537  0.821235  0.025550  0.343075  0.321306 -0.602843   \n",
       "441 -0.956004 -0.938537 -1.535374 -1.711613  1.760535  0.584649  3.654268   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.054499  0.418531 -0.370989  \n",
       "1   -0.830301 -1.436589 -1.938479  \n",
       "2   -0.054499  0.060156 -0.545154  \n",
       "3    0.721302  0.476983 -0.196823  \n",
       "4   -0.054499 -0.672502 -0.980568  \n",
       "..        ...       ...       ...  \n",
       "437 -0.054499  0.655787  0.151508  \n",
       "438  0.721302 -0.380819  0.935254  \n",
       "439 -0.232934 -0.985649  0.325674  \n",
       "440  0.558384  0.936163 -0.545154  \n",
       "441 -0.830301 -0.088752  0.064426  \n",
       "\n",
       "[442 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler().fit(diabetes_df.values)\n",
    "scaled_df = pd.DataFrame(scaler.transform(diabetes_df.values), columns=diabetes_df.columns)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimate value of k\n",
    "inertias = []\n",
    "for i in range(1, 11):\n",
    "  km = KMeans(n_clusters=i, init='random', \n",
    "            n_init=10, max_iter=300, \n",
    "            tol=0.001, random_state=0)\n",
    "  km.fit(scaled_df)\n",
    "  inertias.append(km.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), inertias, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like k=2 would be an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "km = KMeans(n_clusters=2, init='random', \n",
    "            n_init=10, max_iter=300, \n",
    "            tol=0.001, random_state=0)\n",
    "km.fit(scaled_df)\n",
    "predictions = km.predict(scaled_df)\n",
    "cluster = pd.Series(predictions, index=scaled_df.index)\n",
    "scaled_df['cluster'] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "437    1\n",
       "438    1\n",
       "439    0\n",
       "440    1\n",
       "441    0\n",
       "Length: 442, dtype: int32"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustered linear regression approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_cluster(X_train, y_train, X_test, cluster_train, cluster_test, n):\n",
    "  regs = []\n",
    "\n",
    "  X_train_cluster = pd.DataFrame(X_train)\n",
    "  X_train_cluster['cluster'] = cluster_train\n",
    "  y_train_cluster = pd.DataFrame(y_train)\n",
    "  y_train_cluster['cluster'] = cluster_train\n",
    "  X_test_cluster = pd.DataFrame(X_test)\n",
    "  X_test_cluster['cluster'] = cluster_test\n",
    "\n",
    "  for i in range(n):\n",
    "    X_train_cluster_i = X_train['cluster' == i]\n",
    "    y_train_cluster_i = pd.Series(y_train_cluster['cluster' == i]['target'])\n",
    "    regs.append(LinearRegression().fit(X_train_cluster_i, y_train_cluster_i))\n",
    "\n",
    "  def predict_row(row):\n",
    "    return regs[row['cluster']].predict(row)\n",
    "\n",
    "  y_pred = X_test.apply(predict_row, axis=1)\n",
    "  return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-fb56c9030c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_by_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-42190a69f132>\u001b[0m in \u001b[0;36mpredict_by_cluster\u001b[0;34m(X_train, y_train, X_test, cluster_train, cluster_test, n)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_train_cluster_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0my_train_cluster_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_cluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mregs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cluster_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cluster_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "split = kf.split(diabetes_df)\n",
    "mse = []\n",
    "target_df = pd.DataFrame(diabetes_target, columns=['target'])\n",
    "X = diabetes_df.values\n",
    "y = target_df.values\n",
    "for train, test in split:\n",
    "  y_pred = predict_by_cluster(X[train], y[train], X[test], cluster[train], cluster[test], 2)\n",
    "  mse.append(mean_squared_error(y[test], y_pred))\n",
    "sum(mse) / len(mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.055785</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.089244</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.132376</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.023677</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.109883</td>\n",
       "      <td>0.088873</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.074191</td>\n",
       "      <td>0.061054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-0.074533</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.009439</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.021669</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.033246</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.033151</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>0.008063</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.015505</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.028323</td>\n",
       "      <td>-0.075636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>-0.060003</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.049840</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>-0.030124</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>-0.059067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018114</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046883</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044529</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081413</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004222</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "353 -0.052738 -0.044642 -0.055785 -0.036656  0.089244 -0.003193  0.008142   \n",
       "354 -0.023677  0.050680  0.045529  0.021872  0.109883  0.088873  0.000779   \n",
       "355 -0.074533  0.050680 -0.009439  0.014987 -0.037344 -0.021669 -0.013948   \n",
       "356 -0.005515  0.050680 -0.033151 -0.015999  0.008063  0.016222  0.015505   \n",
       "357 -0.060003  0.050680  0.049840  0.018430 -0.016704 -0.030124 -0.017629   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  \n",
       "353  0.034309  0.132376  0.003064  \n",
       "354  0.034309  0.074191  0.061054  \n",
       "355 -0.002592 -0.033246  0.011349  \n",
       "356 -0.002592 -0.028323 -0.075636  \n",
       "357 -0.002592  0.049770 -0.059067  \n",
       "..        ...       ...       ...  \n",
       "437 -0.002592  0.031193  0.007207  \n",
       "438  0.034309 -0.018114  0.044485  \n",
       "439 -0.011080 -0.046883  0.015491  \n",
       "440  0.026560  0.044529 -0.025930  \n",
       "441 -0.039493 -0.004222  0.003064  \n",
       "\n",
       "[89 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78d1d7c2ad17303302b31d4cfbe98a71849bd4d3dda140e402138da0b1ced0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
